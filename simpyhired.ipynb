{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sc = SparkContext()\n",
    "sc=SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.simplyhired.com/job/UUyVXAezLbE_UwtxmOqSa8yh92MbAd_oXQYV-9yKb-jbKveH9jfpDg?q=big+data+engineer\n"
     ]
    }
   ],
   "source": [
    "page1='https://www.simplyhired.com/search?q=big+data+engineer&l=United+States&job=ub4DHpuVXa22bbL-bGMvsmpBEYJyApC38ZwIH6V0WUpOav4oe5RZIA'\n",
    "page2='https://www.simplyhired.com/search?q=big+data+engineer&l=united+states&sb=dd&pn=2&job=MrNtePJJR-mAmQM8Tiba5rnHB16pySp-UvaY0XdiWugpNfotFPsEtQ'\n",
    "pagelist=[page1,page2]\n",
    "\n",
    "mydf=[]\n",
    "for i in pagelist:\n",
    "        page = requests.get(i)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser') # Access on the whole web front-end content\n",
    "        #print(soup)\n",
    "        #print(soup.find_all('a'))# find all links\n",
    "\n",
    "        job_container=soup.find(id=\"job-list\")#fAccess on the job-list container\n",
    "        #print(job_list)\n",
    "\n",
    "        \n",
    "        jobs=job_container.find_all(class_ ='SerpJob')#Accessing all of the job listed\n",
    "        # for i in range(len(jobs)):\n",
    "        #         print(jobs[i].find(class_='jobposting-title-container').get_text())#title,\n",
    "        #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text())#company\n",
    "        #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text())#location\n",
    "        #         print(jobs[i].find(class_='jobposting-salary').get_text())#salary\n",
    "        #         print(jobs[i].find(class_='jobposting-snippet').get_text())#description\n",
    "        #         print(jobs[i].find(class_='SerpJob-timestamp').get_text())#date\n",
    "        #         #print(jobs[i].find(SerpJob-timestamp.datetime))#.get_text())#\n",
    "        #         #print(jobs[i].find_all('a'))# find all links      \n",
    "        #         print()#datetime\n",
    "\n",
    "        \n",
    "        titles=[jobs[i].find(class_='jobposting-title-container').get_text() for i in range(len(jobs))]\n",
    "        companies=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text() for i in range(len(jobs))]\n",
    "        locations=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text() for i in range(len(jobs))]\n",
    "        salaries=[jobs[i].find(class_='SerpJob-metaInfoLeft').get_text() for i in range(len(jobs))]#jobposting-salary\n",
    "        descriptions=[jobs[i].find(class_='jobposting-snippet').get_text() for i in range(len(jobs))]\n",
    "        timestamps=[jobs[i].find(class_='SerpJob-timestamp').get_text() for i in range(len(jobs))]\n",
    "        links=['https://www.simplyhired.com'+jobs[i].find('a').get('href') for i in range(len(jobs))]#\n",
    "        \n",
    "\n",
    "        jobs_df=pd.DataFrame(\n",
    "            {\n",
    "              'titles':titles,  \n",
    "              'companies':companies,\n",
    "              'locations':locations,\n",
    "              'salaries':salaries,\n",
    "              'descriptions':descriptions,\n",
    "              'timestamps':timestamps,\n",
    "              'links':links\n",
    "\n",
    "            })\n",
    "        mydf.append(jobs_df)\n",
    "\n",
    "#print(jobs_df) \n",
    "result = pd.concat(mydf)\n",
    "print(links[6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|              titles|           companies|           locations|            salaries|        descriptions|timestamps|               links|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|Big Data Engineer...|  iLink Systems Inc.|         Dallas, TX |$60 - $75 an hour...|Big Data Engineer...|        4d|https://www.simpl...|\n",
      "|MongoDB Data Engi...|BlueCross BlueShi...|    Chattanooga, TN |Estimated: $65,00...|Ability to apply ...|          |https://www.simpl...|\n",
      "|       Data Engineer|                GMAD|    Los Angeles, CA |$100,000 - $120,0...|Ideal candidate w...|          |https://www.simpl...|\n",
      "|Senior Big Data E...|American Family I...|        Madison, WI |Estimated: $140,0...|R15759 Senior Big...|          |https://www.simpl...|\n",
      "|       Data Engineer|  Equity Residential|        Chicago, IL |Estimated: $110,0...|Partner with stak...|          |https://www.simpl...|\n",
      "|Senior Data Engineer|          Prudential|         Newark, NJ |Estimated: $130,0...|Evaluating big da...|          |https://www.simpl...|\n",
      "|   Sr. Data Engineer|      Texture Health|        Chicago, IL |Estimated: $130,0...|The Senior Data E...|          |https://www.simpl...|\n",
      "|Healthcare Data E...|B.well Connected ...|         Austin, TX |Estimated: $110,0...|Experience in des...|          |https://www.simpl...|\n",
      "|Data Engineer (Re...|            Slync.io|             Remote |Estimated: $110,0...|Experience with b...|          |https://www.simpl...|\n",
      "|GIS/Spatial Data ...|   Inari Agriculture| West Lafayette, IN |Estimated: $97,00...|As a GIS/Spacial ...|          |https://www.simpl...|\n",
      "|Data Engineer (Re...|  The New York Times|       New York, NY |Estimated: $130,0...|Wirecutter is see...|          |https://www.simpl...|\n",
      "|Entry Level Data ...|          Enhance IT|Los Angeles, CA +...|Estimated: $83,00...|Enhance IT is an ...|          |https://www.simpl...|\n",
      "|       Data Engineer|         E-Nor, Inc.|             Remote |Estimated: $100,0...|Google Certified ...|          |https://www.simpl...|\n",
      "|Big Data Systems ...|               Xandr|       New York, NY |Estimated: $100,0...|As a Big Data Sys...|          |https://www.simpl...|\n",
      "|Big Data Systems ...|                AT&T|       New York, NY |Estimated: $110,0...|As a Big Data Sys...|          |https://www.simpl...|\n",
      "|       Data Engineer|             Degreed|             Remote |Estimated: $99,00...|The Data Engineer...|          |https://www.simpl...|\n",
      "|   Big Data Engineer|JAMY INTERACTIVE,...|    Santa Clara, CA |Estimated: $110,0...|Google Big Query,...|          |https://www.simpl...|\n",
      "|Data Integration ...|Cook Children's H...|     Fort Worth, TX |Estimated: $85,00...|The Data Integrat...|          |https://www.simpl...|\n",
      "|Engineer - Data &...|                 PAE| Patuxent River, MD |Estimated: $41,00...|Coordinate with a...|        6d|https://www.simpl...|\n",
      "|Full Stack Developer|             Handled|      St. Louis, MO |Estimated: $88,00...|A strong command ...|     Today|https://www.simpl...|\n",
      "|Engineer - Data &...|                 PAE| Patuxent River, MD |Estimated: $41,00...|Coordinate with a...|        6d|https://www.simpl...|\n",
      "|Data Center Engineer|Watch Communications|     Evansville, IN |Estimated: $70,00...|Watch Communicati...|          |https://www.simpl...|\n",
      "|       Data Engineer|ManTech Internati...|        Herndon, VA |Estimated: $77,00...|Document database...|          |https://www.simpl...|\n",
      "|Technical Data An...|       Comerica Bank|   Auburn Hills, MI |Estimated: $93,00...|8 years of Techni...|          |https://www.simpl...|\n",
      "|Senior GIS Integr...|     AEVEX AEROSPACE|   Fayetteville, NC |Estimated: $98,00...|Displayed ability...|          |https://www.simpl...|\n",
      "|Senior Software Q...|       Vizient, Inc.| Cape Girardeau, MO |Estimated: $73,00...|Perform functiona...|          |https://www.simpl...|\n",
      "|Database Software...|                 CGG|        Houston, TX |Estimated: $81,00...|Familarity with b...|     Today|https://www.simpl...|\n",
      "|       Data Engineer|          Bombardier|       Hartford, CT |Estimated: $110,0...|Integrate data fr...|     Today|https://www.simpl...|\n",
      "|       Data Engineer|               Bayer|   Chesterfield, MO |Estimated: $120,0...|The primary respo...|     Today|https://www.simpl...|\n",
      "|Big Data Cloud En...|               Bayer|      St. Louis, MO |Estimated: $89,00...|Big Data Cloud En...|     Today|https://www.simpl...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#for i in range(len(mydf)):\n",
    "mySchema = StructType([ StructField(\"titles\", StringType(), True)\\\n",
    "                       ,StructField(\"companies\", StringType(), True)\\\n",
    "                       ,StructField(\"locations\", StringType(), True)\\\n",
    "                       ,StructField(\"salaries\", StringType(), True)\\\n",
    "                       ,StructField(\"descriptions\", StringType(), True)\\\n",
    "                       ,StructField(\"timestamps\", StringType(), True)\\\n",
    "                       ,StructField(\"links\", StringType(), True)])\n",
    "df = spark.createDataFrame(result,schema=mySchema)\n",
    "\n",
    "df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the jar to the spark/jar to link spark to mysql\n",
    "df.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=E5cSNSeBhjw\n",
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "#https://hackersandslackers.com/scraping-urls-with-beautifulsoup/\n",
    "#https://opensource.com/article/19/5/log-data-apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
